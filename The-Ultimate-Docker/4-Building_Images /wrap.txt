*** 1- Introduction ***
The first step in using Docker to build and deploy applications is creating images. 
So having a solid understanding of Docker images is crucial for us. And that's what this section is all about.

- We'll be talking about creating Docker files, versioning images, sharing them, saving and
loading them, and a few optimization techniques for reducing the image size and speeding up builds.

In this section:
-------------------code----------------------
• Creating Docker files
• Versioning images
• Sharing images
• Saving and loading images
• Reducing the image size
• Speeding up builds
-------------------code----------------------

*** 2- Images and Containers ***

Alright, before we get started, let's make sure we have the right understanding of
images and containers. 
- Can we define what an image is, and how it's different from a container? 
An image includes everything
an application needs to run. So, it contains a cut down
operating system, like Linux or Windows. It also contains third party libraries,
application files, environment variables and so on. So, an image
contains all the files and configuration settings needed to run
an application. Once we have an image, we can start a container from it.
-------------------code----------------------
IMAGE
• A cut-down OS
• Third-party libraries
• Application files
• Environment variables
-------------------code----------------------

- A container is kind of like a virtual machine in the sense that it provides
an isolated environment for executing an application. And similar
to virtual machines, we can stop and restart containers. Now
technically, a container is just an operating system process, but it's a
special kind of process because it has its own file system which is provided
by the image.
-------------------code----------------------
CONTAINER
• Provides an isolated environment
• Can be stopped & restarted
• Is just a process!
-------------------code----------------------

-  Now, In the previous section we started a container from the Ubuntu image. Now we're going to
open up another terminal window. 
-------------------code----------------------
~  $ docker start -i 8a6
root@8a65a7f2dd58:/#
-------------------code----------------------

- Let's run docker ps to see the running processes or running containers.
So here's the container that we started in the previous section.
-------------------code----------------------
~  $ docker ps
CONTAINER ID   IMAGE     COMMAND       CREATED        STATUS          PORTS     NAMES
8a65a7f2dd58   ubuntu    "/bin/bash"   14 hours ago   Up 45 seconds             eloquent_lichterman
-------------------code----------------------
PS: start command to start and exist container

- Now we're going to start a new container from the same image.
We type docker run, we want to run this in the interactive mode so we can work with it. And then we type
the name of the image, so Ubuntu.
-------------------code----------------------
~  $ docker run -it ubuntu
root@17e332c0bbd7:/#
-------------------code----------------------
PS: to create new container and start it

- here's the container ID and as we can see, this is different from
this other container. Now, back to our first container, we're currently
inside the home directory. So in the previous section we created
a bunch of directories and this deployment file.
-------------------code----------------------
~  $ docker ps
CONTAINER ID   IMAGE     COMMAND       CREATED          STATUS          PORTS     NAMES
c315081d7859   ubuntu    "/bin/bash"   2 seconds ago    Up 1 second               charming_mccarthy
17e332c0bbd7   ubuntu    "/bin/bash"   24 seconds ago   Up 23 seconds             blissful_albattani
-------------------code----------------------

- Now, back to our new container, let's go to the home directory
and see what is here. There's nothing here. Here's the reason. A container gets its file system
from the image, but each container has its own write layer. So what we write in a given container
is invisible from other containers.
-------------------code----------------------
root@17e332c0bbd7:/# cd home/
root@17e332c0bbd7:/home# ls
ubuntu
-------------------code----------------------

- Of course, there is a way to share data between containers and we'll talk about that later in the course.
But what we want to understand here
is that each container is an isolated environment for executing an application.
It's an isolated universe. So whatever happens inside that universe
is invisible to other containers.

*** 3- Sample Web Application ***

- So over the next few lessons, we're going to take a front-end application built with
React and package it into a docker image. 

- To run this project on a new machine, first we have to
install node, then using npm we have to install third party dependencies
and finally, to start the project we have to type npm start. 
-------------------code----------------------
STEPS
• Install Node
• npm install
• npm start
-------------------code----------------------

- We have the same concept in other development stacks. So
whether we use C sharp or java or python or ruby, we have some tool to manage
the dependencies of our application and then we have a way to start our application.

- Here we have to use npm start. So, let's go ahead. This started at development server
listening on port 3000. So if we go to localhost port
3000, we can see our react application. This is just a basic react application
like a brand new project. 
-------------------code----------------------
localhost:3000
-------------------code----------------------

- we haven't done anything here and it doesn't really matter.
Later in the course, we're going to show we a real project that we have built using react
and node. So now that we understand what this project is and how we can
run it on a new machine, let's see how we can
use docker so we don't have to repeat all these steps every time we want to deploy
this on a new machine.

*** 4- Dockerfile Instructions ***
- The first step to dockerize an application is adding a docker file to it.

- what is a docker file?
It contains instructions for building an image.
we saw a few of these instructions before, but let's go through the complete list so we know what is available.
We have from for specifying the base image, so we take that base image
which contains a bunch of files and directories and then we build on top of it.
Then we have workdir for specifying the working directory. Once we use this command,
all the following commands will be executed in the current working directory.
We have copy and add for copying files and directories.
We have run for executing operating system commands. So all the Linux commands
that we talked about in the previous section, we can execute them using run.
Now, if we're on Windows, we can execute Windows commands using run as well.
We have env for setting environment variables, expose for text.
for telling docker that our container is starting on a given port.
User for specifying the user that should run the application.
Typically, we want to run our application using a user with limited privileges.
And we have command and entry point for specifying the command that should be executed
when we start a container. So that's the big picture.
-------------------code----------------------
DOCKERFILE
• FROM                 • ENV
• WORKDIR              • EXPOSE
• COPY                 • USER
• ADD                  • CMD
• RUN                  • ENTRYPOINT
-------------------code----------------------

Now, over the next few lessons, we're going to explore each of these commands in detail.
Pull our basic commands in detail.

*** 5- Choosing the Right Base Image ***

- Alright, let's start off by adding a dockerfile to this project. So,
here in the root of this project, we're going to add a new file called dockerfile.
Now the first instruction we're going to use is from, which we use for specifying the base image. The base image can be an
operating system like Linux or Windows or it can be an operating system
plus a runtime environment. 

- For example, if we're a C sharp developer, we want to start from a dotnet image. If we're a python developer,
we want to start from a python image. If we're a javascript developer, we want to start
from a node image. Now if we google docker samples, we can find
this page.
-------------------code----------------------
docs.docker.com/samples/
-------------------code----------------------

- in the left menu, we can see various examples of docker files for different technology
stacks. For example, for an aspen.net core application,
we can see a docker file. Now look at the from instruction. Over here, we have a full url
instead of an image. Because microsoft images are not hosted on docker
hub. They're hosted in microsoft container registry. That's why we have
MCR, which is short for microsoft container registry.
So an image can be in any registries. The default registry that docker
uses is docker hub. For any images, in other registries,
we have to type the full url. 
-------------------code----------------------
FROM mcr.microsoft.com/dotnet/core/sdk:3.1 AS build-env
-------------------code----------------------

- Now, don't just blindly take this url. Because the url can change, or the version
can change. So always do our own research. So that's one example.
If we're a Django developer, we want to start from
python 3. Or in the future, we might want to use
python 4. Now what about this project? Well, for this project,
we need node. Because as we saw, we need
npm to install the application dependencies and start the application. 

- So let's go to hub.docker.com and search for node.
-------------------code----------------------
hub.docker.com
-------------------code----------------------

- Now this is where things get a little bit interesting.
Because node repository on docker hub has hundreds of node images.
And this can be a little bit confusing. So, let's go to the tags.
Here we can see various node images. So if we scroll down, we can see there are
tons of node images for different versions built on
different versions of Linux.
For example, we have node version 14.16.0
on top of buster which, if we're not wrong, is
Debian Linux version 10.

- So we have different versions of node on different
versions of Linux. The image we should choose really depends on our application.
What version of node do we want to target? We can go to our docker file
and say, we want to start from node and by default, docker
assumes the latest tag. Do not ever use this.
Because if we build our application against the latest version of node, next time there is
a new version of node, if we rebuild our application's image, our application will
be built with a different version of node
and things can get unpredictable. So always use a specific version.
-------------------code----------------------
FROM node:latest
-------------------code----------------------

- So, back to docker hub. Let's say we want to build this application
against node version 14. So here we search for 14. Now once again we have
tens or maybe hundreds of node images for version 14.
Here's one we just talked about. There is more.
We have version 14 on top of buster. So this one doesn't have
the minor build number. It's just a major version number.
Now look at the size of this image. It's around 300 megabytes.
And why do we have multiple items in this list? Well, this image is built
for different operating system and CPU architectures.
So, there's two more here. As we can see, all of these
are built on top of Linux. So as far as we know, we don't have a node image
built on top of Windows. we could be wrong. But if we want to run on top of Windows,
we have to start from a Windows image and then install node on top of it.
There's no reason we want to do this
because Windows images are really large. we think they're over 2 gigabytes.

- So, back to the story. Depending on our CPU architecture,
when we pull an image, docker will automatically download the right docker image
for our CPU architecture, Now, we don't want to use any of these images
because these are way too large. And this is the compressed size.
When this is uncompressed, it's going to be around 1 gigabyte.
we want to go for a smaller image and deployments faster.

- So, on this page, let's search for Alpine.
Earlier we told we that, Alpine images are really small.
Look at this. The compressed size is around 40 megabytes.
This image is almost 10 times smaller than the other image we saw.
Now look at the image tag. It's very specific.
Version 14.16.0 of node, built on top of
Alpine 3.13. we're happy with this version, so we're going to copy this.
And then paste it after the FROM.
-------------------code----------------------
FROM node:14.16.0-alpine3.13
-------------------code----------------------

- So that was the first step.
Now, back to our terminal window, here in the project directory, we're going to build an image.
So, we run docker build dash t for tagging the image.
We're going to call this image react app
and we type a period to tell docker where it can find a docker file.
That means in the current directory.
-------------------code----------------------
docker build -t react-app .
-------------------code----------------------

- Let's go ahead. Okay, the image was built.
So now, we're going to look at all the images
we have on this machine using docker images or docker image ls.
So currently we have three images.
Here's the image that we just built.
-------------------code----------------------
REPOSITORY     TAG       IMAGE ID       CREATED        SIZE
hello-docker   latest    817ba4c523a5   27 hours ago   160MB
<none>         <none>    8af7922e7fd1   27 hours ago   160MB
ubuntu         latest    c3d1a3432580   7 weeks ago    101MB
react-app      latest    322425dfa4aa   3 years ago    116MB
-------------------code----------------------


- Now let's start a container with this image
and see what happens. So docker run, we want to run this in the interactive mode
so we can play with it and the image is react app.
-------------------code----------------------
~  $ docker run -it react-app
Welcome to Node.js v14.16.0.
Type ".help" for more information.
>
-------------------code----------------------

- What's going on here? We're inside a node environment.
So here we can write javascript code and node will execute it.
For example, we can define a constant and then log the constant.
-------------------code----------------------
> const x = 1
undefined
> console.log(x)
1
-------------------code----------------------

- So we're inside a node environment.
We don't want this. We want to run bash
so we can look at the file system. So we press control and see.
Now it says to exit, press control and see one more time.
So the container is stopped. Let's run it one more time.
So docker run interactive react app. Now at the end,
we can specify the command to run
when starting this container. We want to run bash.
Now look. We get an error saying
this module is not found. Why is that?
Because alpine Linux doesn't come with bash. That's why it's a very small
Linux distribution. So it doesn't have many of the utilities
we're familiar with. 
-------------------code----------------------
~  $ docker run -it react-app bash
internal/modules/cjs/loader.js:883
  throw err;
  ^

Error: Cannot find module '/bash'
    at Function.Module._resolveFilename (internal/modules/cjs/loader.js:880:15)
    at Function.Module._load (internal/modules/cjs/loader.js:725:27)
    at Function.executeUserEntryPoint [as runMain] (internal/modules/run_main.js:72:12)
    at internal/main/run_main_module.js:17:47 {
  code: 'MODULE_NOT_FOUND',
  requireStack: []
}
-------------------code----------------------

- Instead of bash, it comes with shell. The original shell program.
So one more time. Docker run interactive
react app. Instead of bash, we're going to use shell.
-------------------code----------------------
~  $ docker run -it react-app sh
/ # ls
bin    dev    etc    home   lib    media  mnt    opt    proc   root   run    sbin   srv    sys    tmp    usr    var
-------------------code----------------------

- Now we're doing a shell session inside this container.
So let's look around. We have all these directors we're familiar with.
So this is alpine Linux and in this image we also have node.
So if we type node dash dash version, we can see the version of node
which is 14.16.0.

- Now in this image we don't have our application files.
We only have alpine Linux and node. So in the next lesson we're going to show we
how to copy application files into this image.
-------------------code----------------------
/ # node --version
v14.16.0
-------------------code----------------------

*** 6- Copying Files and Directories ***

- Now that we have a base image, the next step is to copy the application
files into the image. So for that we have two instructions, one is
copy, the other is add. They have the exact same syntax,
but add has a couple additional features, we'll talk about that later in this lesson.
-------------------code----------------------
ADD 
COPY
-------------------code----------------------

- So, let's start with copy. With this we can copy one or
more files or directories from the current directory, meaning
this directory over here into the image. So we cannot copy
anything outside of this directory. 

- Here's the reason. When we execute the build command, look at the last argument. A period means the
current directory. So when we execute this command, docker client
sends the content of this directory to docker engine. This is called the
build context. So docker client sends the build context to docker
engine, and then docker engine will start executing these commands
one by one. So at that point, docker engine does not have access
to any files or directories outside of this directory.
-------------------code----------------------
docker build -t react-app .
-------------------code----------------------

- So, here we can copy one or more files. For example, we can copy
package.json into slash app into the image. Now if this directory doesn't exist, docker will automatically
create it.
-------------------code----------------------
COPY package.json /app
-------------------code----------------------

-  We can also copy more than one file, so we can say
readme.md, and by the way, remember this is case sensitive because under the hood we are using
Linux. 
-------------------code----------------------
COPY package.json README.md /app
=> when using COPY with more than one source file, the destination must be a directory and end with a / or a \
-------------------code----------------------

- Now here we have a syntax arrow, look, when using
copy with more than one source file the destination must be a directory
and end with a forward slash. So, here we need to add a
forward slash.
-------------------code----------------------
FROM node:14.16.0-alpine3.13
COPY package.json README.md /app/
-------------------code----------------------

- We can also use patterns. So, let's say, we want to copy all files
that start with package and end with json. So, whatever comes in between
we don't care. That's why we're using a wild card. So, in this directory
we have two files that match this pattern we have package-lock.json
and package.json. Package.json as we told we before includes the list of dependencies
and their versions. But the actual versions that may be installed on this machine
might be a little bit different from what we see here.
So, package-lock.json keeps track of the exact version of these dependencies
installed on this machine.
-------------------code----------------------
COPY package*.json /app/
-------------------code----------------------

- Now, what if we want to copy everything in the current directory into the
app directory? We use a period. So, this is all about source files
and directories.
-------------------code----------------------
COPY . /app/
-------------------code----------------------

-  Now, let's talk about the destination. So, here we're using
an absolute path because our path starts with a forward slash.
We can also use a relative path if we set the working directory first.
So, using the workdir instruction we can set the working directory.
Now, all the instructions that come after will be executed inside
this working directory. And with this we can replace this absolute path
with a relative path. So, we can use a period meaning the current directory. Okay?
-------------------code----------------------
WORKDIR /app
COPY . . 
-------------------code----------------------

- Now, one last thing about copy.
What if we want to copy a file that has
a space in it? So, let's say we have a file called hello world
dot txt. Look, we immediately get a syntax error.
-------------------code----------------------
COPY hello world.txt . 
=> when using COPY with more than one source file, the destination must be a directory and end with a / or a 
-------------------code----------------------

- This is where we use the other form of the
copy instruction. So, copy has another form where
we can pass an array of strings.
-------------------code----------------------
["", "", ""]
-------------------code----------------------

- So, multiple strings. Each string represents an
argument of the copy instruction. So, here, we're going to wrap
all these arguments inside brackets. Then, we're going to wrap
the first item, which is our source file in double quotes.
Then, we add a comma, and wrap the second argument in double quotes.
It's not a form that we use that often, but we thought to cover it to make this less
uncomprehending.
-------------------code----------------------
COPY ["hello world.txt", "."]
-------------------code----------------------

- So, let's simplify things. We're going to copy everything
in our context directory, which is the current directory,
into the current working directory of the image. Okay? Now,
we also have add, it has the exact same syntax as copy,
but add has two additional features. 
-------------------code----------------------
COPY . . 
ADD . .
-------------------code----------------------

- With add, we can add a file from a url, so here we can type
http, some url, and let's say some
file.json. So, if we have access to this file, we can add it to our
image. The other feature is that if we pass
a compressed file, add will automatically uncompress this
into a directory. So, we can use either of these instructions, but the
best practice is to use copy, because it's more straightforward, there's no magic
around it. Use that only if we need one of these additional features.
If we want to add a file from a url, or if we want to uncompress a compressed
file. 
-------------------code----------------------
ADD http://.../file.json .
ADD file.zip .
-------------------code----------------------

- So, let's get rid of this. We're going to copy everything
in the current directory into our image. So, let's go ahead and
rebuild our image. 
-------------------code----------------------
FROM node:14.16.0-alpine3.13
WORKDIR /app
COPY . . 
-------------------code----------------------

- Alright, now look at this line.
Transferring context. So, all the files and directors
in our current directory are being sent to docker engine.
Alright, the image is built, so let's start the container with this image.
-------------------code----------------------
app [master] $ docker build -t react-app .
[+] Building 1.8s (8/8) FINISHED                                                                                                   docker:desktop-linux
 => [internal] load build definition from Dockerfile                                                                                               0.0s
 => => transferring dockerfile: 125B                                                                                                               0.0s
 => [internal] load metadata for docker.io/library/node:14.16.0-alpine3.13                                                                         1.7s
 => [internal] load .dockerignore                                                                                                                  0.0s
 => => transferring context: 2B                                                                                                                    0.0s
 => CACHED [1/3] FROM docker.io/library/node:14.16.0-alpine3.13@sha256:2c51dc462a02f15621e7486774d36d048a27225d581374b002b8477a79a59b4b            0.0s
 => [internal] load build context                                                                                                                  0.0s
 => => transferring context: 546.22kB                                                                                                              0.0s
 => [2/3] WORKDIR /app                                                                                                                             0.0s
 => [3/3] COPY . .                                                                                                                                 0.0s
 => exporting to image                                                                                                                             0.0s
 => => exporting layers                                                                                                                            0.0s
 => => writing image sha256:8816b1815607d3d204cd7f33a3fc141a29e6f96809a6a9a932af2bc578a20463                                                       0.0s
 => => naming to docker.io/library/react-app                                                                                                       0.0s
-------------------code----------------------

- we're going to run shell, so we can look at the file
system. Okay, look, we're inside the app directory,
because in our docker file, we set this directory as the current working
directory. Now, let's run ls. So, here we can see all the files
and directories we have in our project, including node modules.
So, this is all about copying files.
-------------------code----------------------
~  $ docker run -it react-app sh
/app # ls
Dockerfile    README.md     package.json  public        src           yarn.lock
-------------------code----------------------

*** 7- Excluding Files and Directories ***

- In the last lesson we saw that when we build our application, docker
client takes everything in this directory which is called the build context or
the context directory. So docker client takes everything here and sends
it to docker engine or docker daemon. 

- Now for this simple application which has absolutely no features, our build context was about
150 megabytes. But why is it so large? That's the
result of the node modules directory. So if we look over here, we can see
tons of directories and sub directories and this is a very simple project.

- As our application gets more complex and we use more third party
libraries, this node modules directory gets larger and larger. Now
there's a problem here. Later in the course when we talk about deployment, we will see
that our docker client will talk to a docker engine on a different machine.
So that means whatever we have in the build context has to be transferred
over the network. So if we have a large build context with a million files
in it, all these files have to be sent to the docker engine on the remote machine.
We don't want that. We don't really need to transfer this node modules directory
because all these dependencies are defined in package.json. So we can simply exclude this directory
and copy everything else and then restore these dependencies on the target
image. 

- And this has two benefits. The first benefit is that our build context
is smaller. So we transfer less data over the network.
The second benefit is that our build is going to be faster. So we don't have to wait
for all these files to be transferred to docker engine.

- Now how do we exclude this directory? Very easy. we are probably familiar
with the file ".gitignore" With this file, we can exclude some files and directories
from git. Now we have the same concept in docker. So we can
create a file in the root of this project called ignore and everything
is in lowercase. And here we can list the files and directories that should be excluded.
-------------------code----------------------
.dockerignore
-------------------code----------------------
 
- So we can exclude node modules.
Now, when we build a new image, docker will no longer transfer
this large gigantic directory to docker engine. Let's take a look.
So, we're going to run the build command one more time.
-------------------code----------------------
node_modules
-------------------code----------------------

- Look at our build context. It's only 10 kilobytes. So we reduce
our build context from 150 megabytes to 10 kilobytes.
That's a huge improvement. There is a problem though. If we start
a new container and look at the file system
of that container, we're not going to see
the node modules directory because we excluded
it, Let's verify it. 

- So, we're going to run a new container
from react app and then run shell inside that container.
Now in the app directory, let's look at all the files and directories.
Look, we only have two directories here, public and source. So node modules
is not here. This is where we need to run
npm install to install this dependencies. And that's what we will do next.
-------------------code----------------------
/app # ls
Dockerfile    README.md     package.json  public        src           yarn.lock
-------------------code----------------------

*** 8- Running Commands ***

- Alright, the next step is to install
our project dependencies using npm. This is where we use the run command.

- With this command, we can execute any commands that we normally execute
in a terminal session. So we can run npm install, we can also run any of the Linux or Windows commands.
For example, let's say we want to install Python on this image as well.
We can use apt or apt-get to install Python.
-------------------code----------------------
RUN npm install
RUN apt install python
-------------------code----------------------
- Now if we run this, we're going to get an error because alpine Linux doesn't have
apt package manager. It has another package manager called
APK. So be aware of these differences depending on the type of Linux
or Windows we're using.

- So, we don't need to do this in this lesson. Let's just install the dependencies of our project.
So, now, back to our terminal, let's rebuild the image.
-------------------code----------------------
FROM node:14.16.0-alpine3.13
WORKDIR /app
COPY . . 
RUN npm install
-------------------code----------------------

- Alright, so now, docker engine is running npm install to download and install
these dependencies. This is going to take a few seconds, our image is ready.
-------------------code----------------------
app [master] $ docker build -t react-app .
[+] Building 10.5s (7/8)                                                                                                           docker:desktop-linux
 => [internal] load build definition from Dockerfile                                                                                               0.0s
 => => transferring dockerfile: 141B                                                                                                               0.0s
 => [internal] load metadata for docker.io/library/node:14.16.0-alpine3.13                                                                         4.7s
 => [internal] load .dockerignore                                                                                                                  0.0s
 => => transferring context: 89B                                                                                                                   0.0s
 => [1/4] FROM docker.io/library/node:14.16.0-alpine3.13@sha256:2c51dc462a02f15621e7486774d36d048a27225d581374b002b8477a79a59b4b                   0.0s
 => [internal] load build context                                                                                                                  0.0s
 => => transferring context: 1.67kB                                                                                                                0.0s
 => CACHED [2/4] WORKDIR /app                                                                                                                      0.0s
 => [3/4] COPY . .                                                                                                                                 0.0s
 => [4/4] RUN npm install                                                                                                                          5.7s
 => => # npm WARN deprecated
 .....
-------------------code----------------------

- So, let's start a new container with this image
and run shell. Good. Now let's look at our app directory.
Alright, and here we have the node modules directory.
Beautiful. So, we're done with this step.
-------------------code----------------------
~  $ docker run -it react-app sh
/app # ls
Dockerfile         node_modules       package.json       src
README.md          package-lock.json  public             yarn.lock
-------------------code----------------------

*** 9- Setting Environment Variables ***

- Sometimes we need to set environment variables. For example, let's say
this frontend application needs to talk to a backend or an API.

- Quite often we set the URL of the API using an environment variable.
This is where we use the end instruction, so we can set API URL to, let's say, http, api
my-app.com, whatever, doesn't really matter.
-------------------code----------------------
ENV API_URL=http://api.myapp.com/
-------------------code----------------------

- We also have an older syntax without an equal sign that also works.
-------------------code----------------------
ENV API_URL http://api.myapp.com/
-------------------code----------------------

- personally prefer to have an equal sign so we can clearly see the value
of environment variables, but that's just my personal preference.

- Now, let's rebuild the image and inspect this environment variable in our
container. So, we're going to rebuild the image.
-------------------code----------------------
FROM node:14.16.0-alpine3.13
WORKDIR /app
COPY . . 
RUN npm install
ENV API_URL=http://api.myapp.com/
-------------------code----------------------

- the image is built, so let's start a new container.
Now, do we remember the command that we use for inspecting environment variables?
We have a few options. One way is to use printenv to see all environment variables, so we can see
API URL over here.
-------------------code----------------------
~  $ docker run -it react-app sh
/app # printenv API_URL
http://api.myapp.com/
-------------------code----------------------

- We can also print the value of a particular environment variable. Another option is to use
echo, but here we have to use a dollar sign to print API
URL.
-------------------code----------------------
/app # echo $API_URL
http://api.myapp.com/
-------------------code----------------------

- so now whenever we start this container,
this environment variable is automatically set for us.

*** 10- Exposing Ports ***

Alright, let's take a quick break from our
docker file and start this application outside of docker. The way we have
always started it. So, from the project directory we run npm
start. 
-------------------code----------------------
npm start
> react-app@o.1.0 start 
> react-scripts start
-------------------code----------------------

-  Now this starts at development server
on port 3000, so if we go to local host port 3000, we can access this application. Now in the future
when we run this application inside a docker container, this port
3000 will be open on the container, not on the host.
-------------------code----------------------
localhost:3000
-------------------code----------------------

- This is something important we need to understand. So on the same machine
we can have multiple containers running the same image. All these containers
will be listening to port 3000, but the port 3000 on the host
is not going to be automatically mapped to these containers. So later,
in the next section we will see how to map a port on the host
to a port on these containers.
-------------------code----------------------
EXPOSE 3000
-------------------code----------------------

-  But for now we're going to go back to our docker
file and use the expose command to tell what port this container
will be listening on. That is port 3000.

- So, the expose command doesn't automatically publish the port on the host, it's just a form
of documentation to tell us this container
will eventually listen on port 3000. So later
when we properly run this application inside a docker container
we know that we should map a port on the host
to port 3000 on the container. We'll do that in the next section.

*** 11- Setting the User ***

- Alright, now let's talk about users.
So by default, docker runs our application with the root user
that has the highest privileges. 

- So that can open up security holes in our
system. So to run this application, we should create a regular user
with limited privileges. 

- But before doing that in the docker file,
let's open up a shell session on Alpine Linux and play with a few commands.
Now, , we're going to run docker run in the interactive mode
Alpine. So here we have a shell session.
-------------------code----------------------
$ docker run -it alpine
-------------------code----------------------

-  Now, in this image, we don't have the user add command.
-------------------code----------------------
/ # useradd
/bin/sh: useradd: not found
-------------------code----------------------

- Instead we have add user, So,
look at these options. There are two options we're going to use.
One of them is dash g for setting the primary group of the user
and the other is dash s for creating a system user.
-------------------code----------------------
/ # adduser
BusyBox v1.37.0 (2025-01-17 18:12:01 UTC) multi-call binary.

Usage: adduser [OPTIONS] USER [GROUP]

Create new user, or add USER to GROUP

	-h DIR		Home directory
	-g GECOS	GECOS field
	-s SHELL	Login shell
	-G GRP		Group
	-S		Create a system user
	-D		Don't assign a password
	-H		Don't create home directory
	-u UID		User id
	-k SKEL		Skeleton directory (/etc/skel)
-------------------code----------------------

- We're going to use a system user because this user is not a real user,
it's just for running an application.

- Now, before using this command, we have to create a group
so we can add this user to that group So to do that, we're going to use add group.
We're going to give this group a name, let's say app.
-------------------code----------------------
/ # addgroup app
-------------------code----------------------

- Now we can run add user, dash s for creating a system user,
dash g for setting the primary group, which is app,
and finally we specify the name of the user.
We're going to use the same name. This is a common best practice in Linux.
So whenever we create a new user, we create a primary group for that user with the same name, okay?
-------------------code----------------------
/ # adduser -S -G app app
-------------------code----------------------

- Now we have a new user, let's verify that this user is in the right group.
So we type groups, app. This shows the groups for the app user.
-------------------code----------------------
/ # groups app
app
-------------------code----------------------

- Now we're going to combine these two commands
into a single command. So let's create another group and a user.
We type add group, we can say moody or whatever,
we use double ampersand to combine two commands,
So we used a single command to perform two tasks.
-------------------code----------------------
addgroup moody && adduser -S -G moody moody
-------------------code----------------------

- Now, let's verify the groups for moody. So this is the command
that we're going to run in our docker file.
-------------------code----------------------
/ # groups moody
moody
-------------------code----------------------

- So let's copy this, now, back to our docker file,
we're going to run a command. How do we do this?
We use the run instruction. Then we paste our command,
and instead of moody, we're going to use app.
So we're going to create a group and a user called app,
Once we do that, then we can set the user using the user command.
So all the following commands will be executed using this user.
-------------------code----------------------
RUN addgroup app && adduser -S -G app app
USER app
-------------------code----------------------

- Let's rebuild our image. So, here's the build command,
let's go ahead. Alright, our image is ready.
Now look at the fifth step. That is our run command
for creating a new group and a new user.
-------------------code----------------------
$ docker build -t react-app .
[+] Building 30.9s (10/10) FINISHED                                                                                                docker:desktop-linux
 => [internal] load build definition from Dockerfile                                                                                               0.0s
 => => transferring dockerfile: 241B                                                                                                               0.0s
 => [internal] load metadata for docker.io/library/node:14.16.0-alpine3.13                                                                         1.7s
 => [internal] load .dockerignore                                                                                                                  0.0s
 => => transferring context: 89B                                                                                                                   0.0s
 => [1/5] FROM docker.io/library/node:14.16.0-alpine3.13@sha256:2c51dc462a02f15621e7486774d36d048a27225d581374b002b8477a79a59b4b                   0.0s
 => [internal] load build context                                                                                                                  0.0s
 => => transferring context: 1.31MB                                                                                                                0.0s
 => CACHED [2/5] WORKDIR /app                                                                                                                      0.0s
 => [3/5] COPY . .                                                                                                                                 0.0s
 => [4/5] RUN npm install                                                                                                                         26.9s
 => [5/5] RUN addgroup app && adduser -S -G app app                                                                                                0.1s
 => exporting to image                                                                                                                             2.1s
 => => exporting layers                                                                                                                            2.1s
 => => writing image sha256:7072f2f889bc06c712fdd966582f8c8c97b0727b02c26926021af2ecf05c3856                                                       0.0s
 => => naming to docker.io/library/react-app
-------------------code----------------------

- Now, we might have noticed that building this image
took probably a long time.
That was because of the step. Installing the dependencies.
Now, we might argue that earlier, we excluded the node modules directory
so our builds would be faster. But our builds are still slow
because every time we build this image, all these dependencies
have to be installed. Don't worry about that. We're going to optimize
this later in this section.

- Now, let's start a new container
and make sure the current user is the app user,
not the root user, So, docker run in the interactive mode,
we're going to run react app and start a shell session.
-------------------code----------------------
$ docker run -it react-app sh
-------------------code----------------------

- we check the current user So, it's the app user.
-------------------code----------------------
/app $ whoami
app
-------------------code----------------------

- Now, let's look at something interesting.
we're going to get a long listing.
These are the files in our application.
Now, all these files, as we can see, are owned by the root user.
And in this column, we can see the permissions
of the root user. So, the root user
can write to any of these files or directories,
but the current user running this session is the app user.
So, this user falls into the others group.
That means the app user is not able to write to any of these files.
-------------------code----------------------
/app $ ls -l
total 1272
-rw-r--r--    1 root     root           165 Mar 20 02:24 Dockerfile
-rw-r--r--    1 root     root          3362 Mar 18 06:18 README.md
drwxr-xr-x 1115 root     root         36864 Mar 20 02:25 node_modules
-rw-r--r--    1 root     root        757495 Mar 20 02:25 package-lock.json
-rw-r--r--    1 root     root           813 Mar 18 06:18 package.json
drwxr-xr-x    2 root     root          4096 Mar 18 06:18 public
drwxr-xr-x    2 root     root          4096 Mar 18 06:18 src
-rw-r--r--    1 root     root        485703 Mar 20 02:16 yarn.lock
-------------------code----------------------

- In contrast, if we executed this application
with the root user, a hacker could potentially
rewrite something in our application.

*** 12- Defining Entrypoints ***

- All right, our docker file is almost ready.
Now how do we start our application? Well, earlier we saw that. Here in the
project directory, we can start the application by running npm start.
-------------------code----------------------
npm start
-------------------code----------------------

- So this is the command that we should execute when starting a container.
So, let's start a container, docker run. Now we're not going to use the interactive mode because we don't want to interact with this container.
We're not going to run a shell session. We just want to start the application.
So, we type the image name. Now let's see if we execute
this command up to this point. Our container
started and then stopped because we didn't specify a command or
a program to execute. 
-------------------code----------------------
$ docker run react-app
-------------------code----------------------

- So this is where we're going to type npm start. Take a look.
All right, we got a permission error. Look over here. Permission denied.
-------------------code----------------------
$ docker run react-app npm start

> react-app@0.1.0 start /app
> react-scripts start

ℹ ｢wds｣: Project is running at http://172.17.0.2/
ℹ ｢wds｣: webpack output is served from
ℹ ｢wds｣: Content not from webpack is served from /app/public
ℹ ｢wds｣: 404s will fallback to /
Starting the development server...

Failed to compile.

EACCES: permission denied, mkdir '/app/node_modules/.cache'
-------------------code----------------------

- why we're getting this error?
In our docker file, we set the user at the end. So we executed
all these previous instructions as the root user,
but then we switched to a regular user with limited privileges.
-------------------code----------------------
FROM node:14.16.0-alpine3.13
WORKDIR /app
COPY . . 
RUN npm install
ENV API_URL=http://api.myapp.com/
EXPOSE 3000
RUN addgroup app && adduser -S -G app app
USER app
-------------------code----------------------

- So, we should move these two lines on the top. So first,
we set the user, then we create the working directory, copy files, and so on.
-------------------code----------------------
FROM node:14.16.0-alpine3.13
RUN addgroup app && adduser -S -G app app
USER app
WORKDIR /app
COPY . . 
RUN npm install
ENV API_URL=http://api.myapp.com/
EXPOSE 3000
-------------------code----------------------

- Now we have to rebuild our image and start a new container.
All right, our image is ready.
-------------------code----------------------
$ docker build -t react-app .
-------------------code----------------------

- So, let's start a new container.
All right, our web server started on port 3000, but as we told before,
this is port 3000 of the container, not local host.
So, if we go to "3000" address, we're not going to be able to access the application.
In the next section, we will show we how to map a port from the host
to a port on the container.
-------------------code----------------------
$ docker run react-app npm start

> react-app@0.1.0 start /app
> react-scripts start

ℹ ｢wds｣: Project is running at http://172.17.0.2/
ℹ ｢wds｣: webpack output is served from
ℹ ｢wds｣: Content not from webpack is served from /app/public
ℹ ｢wds｣: 404s will fallback to /
Starting the development server...

Compiled successfully!

You can now view react-app in the browser.

  Local:            http://localhost:3000
  On Your Network:  http://172.17.0.2:3000

Note that the development build is not optimized.
To create a production build, use yarn build.
-------------------code----------------------

- let's stop this process. Let's bring up
the run command. Now, here's a problem.
We don't want to have to specify this command every time we start a container.
This is where we use the command instruction.
-------------------code----------------------
$ docker run react-app npm start
-------------------code----------------------

- So, back to our docker file, at the end,
using the command instruction, we can supply a default command to be executed.
So, npm start. Now, back to the terminal,
once we rebuild the image, then we can start a container
by simply running docker run react app.
We don't have to specify the command every time.
-------------------code----------------------
CMD npm start
-------------------code----------------------

- Just remember, because the command instruction is for supplying the default command,
it doesn't make sense to have multiple command instructions
in a docker file. If we have multiple command instructions,
only the last one will take effect. Be aware of that.

- Now, we might be wondering, what is the difference between
the command instruction CMD and RUN? Because with both these,
we can execute commands. Here's the difference.
The run instruction is a build time instruction.
So, this is executed at the time of building the image.
So, when building the image, we're installing npm dependencies,
and these dependencies are stored in the image.
In contrast, the command instruction is a runtime instruction.
So, it's executed when starting a container.

- Now, this command instruction has two forms. What we see here
is called the shell form. We also have
another form called execute form, which takes an array of strings. So,
npm and start.
-------------------code----------------------
CMD [ "npm", "start" ]
-------------------code----------------------

- What is the difference? Well,
if we use this syntax, docker will execute this command
inside a separate shell. That is why it's called
the shell form. Now, on Linux, that shell is
slash bin slash shell, the original shell program. On Windows,
it's cmd or command prompt.
Now, the common best practice is to use the execute form
because with this, we can execute this command directly
and there's no need to spin up another shell process.
Also, this makes it easier and faster to clean up resources when we stop containers.
So, always use the execute form.
-------------------code----------------------
# Shell form
# /bin/sh -> Linux
# cmd -> Windows
CMD npm start

# Exec form
CMD [ "npm", "start" ]
-------------------code----------------------

-  here's our command instruction. Now,
we also have another instruction called entry point,
which is very similar to command.
So, it has two forms, the shell form or the execute form.
So, it takes an array of strings. Now,
-------------------code----------------------
# Shell form
ENTRYPOINT npm start

# Exec form
ENTRYPOINT [ "npm", "start" ]
-------------------code----------------------

- what is the difference? Well,
we can always overwrite the default command when starting a container with CMD.
So, back to the terminal, when we run this container,
we can supply another command. So, we can say echo hello and this will overwrite
this command over here.
So, for the same reason, here we can run
a shell session and of course, we want to use the interactive mode.
-------------------code----------------------
$ docker run react-app echo hello
-------------------code----------------------

- Now, in contrast, we cannot easily overwrite the entry point
when running a container. If we want to do that,
we have to use the entry point option.
Now, a lot of people forget to use this. That's why it's a little bit harder
to overwrite the entry point.
-------------------code----------------------
$ docker run react-app --entrypoint
-------------------code----------------------

- So, in practical terms,
we often want to use entry point
when we know for sure that this is the command
or this is the program that should be executed whenever we start a container.
There is no exception.


- In contrast, with the command instruction "CMD", we have
a bit more flexibility. we can always overwrite it. So,
we want to use this instruction for executing ad hoc commands in a container.
Now, which instruction we use is a matter of personal preference.
With both these instructions, we can supply a default command. Some people prefer
the command instruction, other people prefer the entry point. we personally prefer
the former.

- our docker file is in good shape, but if we have noticed,
our builds are slow. We'll talk about
optimizing them next.
-------------------code----------------------
FROM node:14.16.0-alpine3.13
RUN addgroup app && adduser -S -G app app
USER app
WORKDIR /app
COPY . . 
RUN npm install
ENV API_URL=http://api.myapp.com/
EXPOSE 3000
CMD [ "npm", "start" ]
-------------------code----------------------