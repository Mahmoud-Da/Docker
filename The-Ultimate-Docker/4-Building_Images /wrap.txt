*** 1- Introduction ***
The first step in using Docker to build and deploy applications is creating images. 
So having a solid understanding of Docker images is crucial for us. And that's what this section is all about.

- We'll be talking about creating Docker files, versioning images, sharing them, saving and
loading them, and a few optimization techniques for reducing the image size and speeding up builds.

In this section:
-------------------code----------------------
• Creating Docker files
• Versioning images
• Sharing images
• Saving and loading images
• Reducing the image size
• Speeding up builds
-------------------code----------------------

*** 2- Images and Containers ***

Alright, before we get started, let's make sure we have the right understanding of
images and containers. 
- Can we define what an image is, and how it's different from a container? 
An image includes everything
an application needs to run. So, it contains a cut down
operating system, like Linux or Windows. It also contains third party libraries,
application files, environment variables and so on. So, an image
contains all the files and configuration settings needed to run
an application. Once we have an image, we can start a container from it.
-------------------code----------------------
IMAGE
• A cut-down OS
• Third-party libraries
• Application files
• Environment variables
-------------------code----------------------

- A container is kind of like a virtual machine in the sense that it provides
an isolated environment for executing an application. And similar
to virtual machines, we can stop and restart containers. Now
technically, a container is just an operating system process, but it's a
special kind of process because it has its own file system which is provided
by the image.
-------------------code----------------------
CONTAINER
• Provides an isolated environment
• Can be stopped & restarted
• Is just a process!
-------------------code----------------------

-  Now, In the previous section we started a container from the Ubuntu image. Now we're going to
open up another terminal window. 
-------------------code----------------------
~  $ docker start -i 8a6
root@8a65a7f2dd58:/#
-------------------code----------------------

- Let's run docker ps to see the running processes or running containers.
So here's the container that we started in the previous section.
-------------------code----------------------
~  $ docker ps
CONTAINER ID   IMAGE     COMMAND       CREATED        STATUS          PORTS     NAMES
8a65a7f2dd58   ubuntu    "/bin/bash"   14 hours ago   Up 45 seconds             eloquent_lichterman
-------------------code----------------------
PS: start command to start and exist container

- Now we're going to start a new container from the same image.
We type docker run, we want to run this in the interactive mode so we can work with it. And then we type
the name of the image, so Ubuntu.
-------------------code----------------------
~  $ docker run -it ubuntu
root@17e332c0bbd7:/#
-------------------code----------------------
PS: to create new container and start it

- here's the container ID and as we can see, this is different from
this other container. Now, back to our first container, we're currently
inside the home directory. So in the previous section we created
a bunch of directories and this deployment file.
-------------------code----------------------
~  $ docker ps
CONTAINER ID   IMAGE     COMMAND       CREATED          STATUS          PORTS     NAMES
c315081d7859   ubuntu    "/bin/bash"   2 seconds ago    Up 1 second               charming_mccarthy
17e332c0bbd7   ubuntu    "/bin/bash"   24 seconds ago   Up 23 seconds             blissful_albattani
-------------------code----------------------

- Now, back to our new container, let's go to the home directory
and see what is here. There's nothing here. Here's the reason. A container gets its file system
from the image, but each container has its own write layer. So what we write in a given container
is invisible from other containers.
-------------------code----------------------
root@17e332c0bbd7:/# cd home/
root@17e332c0bbd7:/home# ls
ubuntu
-------------------code----------------------

- Of course, there is a way to share data between containers and we'll talk about that later in the course.
But what we want to understand here
is that each container is an isolated environment for executing an application.
It's an isolated universe. So whatever happens inside that universe
is invisible to other containers.

*** 3- Sample Web Application ***

- So over the next few lessons, we're going to take a front-end application built with
React and package it into a docker image. 

- To run this project on a new machine, first we have to
install node, then using npm we have to install third party dependencies
and finally, to start the project we have to type npm start. 
-------------------code----------------------
STEPS
• Install Node
• npm install
• npm start
-------------------code----------------------

- We have the same concept in other development stacks. So
whether we use C sharp or java or python or ruby, we have some tool to manage
the dependencies of our application and then we have a way to start our application.

- Here we have to use npm start. So, let's go ahead. This started at development server
listening on port 3000. So if we go to localhost port
3000, we can see our react application. This is just a basic react application
like a brand new project. 
-------------------code----------------------
localhost:3000
-------------------code----------------------

- we haven't done anything here and it doesn't really matter.
Later in the course, we're going to show we a real project that we have built using react
and node. So now that we understand what this project is and how we can
run it on a new machine, let's see how we can
use docker so we don't have to repeat all these steps every time we want to deploy
this on a new machine.

*** 4- Dockerfile Instructions ***
- The first step to dockerize an application is adding a docker file to it.

- what is a docker file?
It contains instructions for building an image.
we saw a few of these instructions before, but let's go through the complete list so we know what is available.
We have from for specifying the base image, so we take that base image
which contains a bunch of files and directories and then we build on top of it.
Then we have workdir for specifying the working directory. Once we use this command,
all the following commands will be executed in the current working directory.
We have copy and add for copying files and directories.
We have run for executing operating system commands. So all the Linux commands
that we talked about in the previous section, we can execute them using run.
Now, if we're on Windows, we can execute Windows commands using run as well.
We have env for setting environment variables, expose for text.
for telling docker that our container is starting on a given port.
User for specifying the user that should run the application.
Typically, we want to run our application using a user with limited privileges.
And we have command and entry point for specifying the command that should be executed
when we start a container. So that's the big picture.
-------------------code----------------------
DOCKERFILE
• FROM                 • ENV
• WORKDIR              • EXPOSE
• COPY                 • USER
• ADD                  • CMD
• RUN                  • ENTRYPOINT
-------------------code----------------------

Now, over the next few lessons, we're going to explore each of these commands in detail.
Pull our basic commands in detail.

*** 5- Choosing the Right Base Image ***

- Alright, let's start off by adding a dockerfile to this project. So,
here in the root of this project, we're going to add a new file called dockerfile.
Now the first instruction we're going to use is from, which we use for specifying the base image. The base image can be an
operating system like Linux or Windows or it can be an operating system
plus a runtime environment. 

- For example, if we're a C sharp developer, we want to start from a dotnet image. If we're a python developer,
we want to start from a python image. If we're a javascript developer, we want to start
from a node image. Now if we google docker samples, we can find
this page.
-------------------code----------------------
docs.docker.com/samples/
-------------------code----------------------

- in the left menu, we can see various examples of docker files for different technology
stacks. For example, for an aspen.net core application,
we can see a docker file. Now look at the from instruction. Over here, we have a full url
instead of an image. Because microsoft images are not hosted on docker
hub. They're hosted in microsoft container registry. That's why we have
MCR, which is short for microsoft container registry.
So an image can be in any registries. The default registry that docker
uses is docker hub. For any images, in other registries,
we have to type the full url. 
-------------------code----------------------
FROM mcr.microsoft.com/dotnet/core/sdk:3.1 AS build-env
-------------------code----------------------

- Now, don't just blindly take this url. Because the url can change, or the version
can change. So always do our own research. So that's one example.
If we're a Django developer, we want to start from
python 3. Or in the future, we might want to use
python 4. Now what about this project? Well, for this project,
we need node. Because as we saw, we need
npm to install the application dependencies and start the application. 

- So let's go to hub.docker.com and search for node.
-------------------code----------------------
hub.docker.com
-------------------code----------------------

- Now this is where things get a little bit interesting.
Because node repository on docker hub has hundreds of node images.
And this can be a little bit confusing. So, let's go to the tags.
Here we can see various node images. So if we scroll down, we can see there are
tons of node images for different versions built on
different versions of Linux.
For example, we have node version 14.16.0
on top of buster which, if we're not wrong, is
Debian Linux version 10.

- So we have different versions of node on different
versions of Linux. The image we should choose really depends on our application.
What version of node do we want to target? We can go to our docker file
and say, we want to start from node and by default, docker
assumes the latest tag. Do not ever use this.
Because if we build our application against the latest version of node, next time there is
a new version of node, if we rebuild our application's image, our application will
be built with a different version of node
and things can get unpredictable. So always use a specific version.
-------------------code----------------------
FROM node:latest
-------------------code----------------------

- So, back to docker hub. Let's say we want to build this application
against node version 14. So here we search for 14. Now once again we have
tens or maybe hundreds of node images for version 14.
Here's one we just talked about. There is more.
We have version 14 on top of buster. So this one doesn't have
the minor build number. It's just a major version number.
Now look at the size of this image. It's around 300 megabytes.
And why do we have multiple items in this list? Well, this image is built
for different operating system and CPU architectures.
So, there's two more here. As we can see, all of these
are built on top of Linux. So as far as we know, we don't have a node image
built on top of Windows. we could be wrong. But if we want to run on top of Windows,
we have to start from a Windows image and then install node on top of it.
There's no reason we want to do this
because Windows images are really large. we think they're over 2 gigabytes.

- So, back to the story. Depending on our CPU architecture,
when we pull an image, docker will automatically download the right docker image
for our CPU architecture, Now, we don't want to use any of these images
because these are way too large. And this is the compressed size.
When this is uncompressed, it's going to be around 1 gigabyte.
we want to go for a smaller image and deployments faster.

- So, on this page, let's search for Alpine.
Earlier we told we that, Alpine images are really small.
Look at this. The compressed size is around 40 megabytes.
This image is almost 10 times smaller than the other image we saw.
Now look at the image tag. It's very specific.
Version 14.16.0 of node, built on top of
Alpine 3.13. we're happy with this version, so we're going to copy this.
And then paste it after the FROM.
-------------------code----------------------
FROM node:14.16.0-alpine3.13
-------------------code----------------------

- So that was the first step.
Now, back to our terminal window, here in the project directory, we're going to build an image.
So, we run docker build dash t for tagging the image.
We're going to call this image react app
and we type a period to tell docker where it can find a docker file.
That means in the current directory.
-------------------code----------------------
docker build -t react-app .
-------------------code----------------------

- Let's go ahead. Okay, the image was built.
So now, we're going to look at all the images
we have on this machine using docker images or docker image ls.
So currently we have three images.
Here's the image that we just built.
-------------------code----------------------
REPOSITORY     TAG       IMAGE ID       CREATED        SIZE
hello-docker   latest    817ba4c523a5   27 hours ago   160MB
<none>         <none>    8af7922e7fd1   27 hours ago   160MB
ubuntu         latest    c3d1a3432580   7 weeks ago    101MB
react-app      latest    322425dfa4aa   3 years ago    116MB
-------------------code----------------------


- Now let's start a container with this image
and see what happens. So docker run, we want to run this in the interactive mode
so we can play with it and the image is react app.
-------------------code----------------------
~  $ docker run -it react-app
Welcome to Node.js v14.16.0.
Type ".help" for more information.
>
-------------------code----------------------

- What's going on here? We're inside a node environment.
So here we can write javascript code and node will execute it.
For example, we can define a constant and then log the constant.
-------------------code----------------------
> const x = 1
undefined
> console.log(x)
1
-------------------code----------------------

- So we're inside a node environment.
We don't want this. We want to run bash
so we can look at the file system. So we press control and see.
Now it says to exit, press control and see one more time.
So the container is stopped. Let's run it one more time.
So docker run interactive react app. Now at the end,
we can specify the command to run
when starting this container. We want to run bash.
Now look. We get an error saying
this module is not found. Why is that?
Because alpine Linux doesn't come with bash. That's why it's a very small
Linux distribution. So it doesn't have many of the utilities
we're familiar with. 
-------------------code----------------------
~  $ docker run -it react-app bash
internal/modules/cjs/loader.js:883
  throw err;
  ^

Error: Cannot find module '/bash'
    at Function.Module._resolveFilename (internal/modules/cjs/loader.js:880:15)
    at Function.Module._load (internal/modules/cjs/loader.js:725:27)
    at Function.executeUserEntryPoint [as runMain] (internal/modules/run_main.js:72:12)
    at internal/main/run_main_module.js:17:47 {
  code: 'MODULE_NOT_FOUND',
  requireStack: []
}
-------------------code----------------------

- Instead of bash, it comes with shell. The original shell program.
So one more time. Docker run interactive
react app. Instead of bash, we're going to use shell.
-------------------code----------------------
~  $ docker run -it react-app sh
/ # ls
bin    dev    etc    home   lib    media  mnt    opt    proc   root   run    sbin   srv    sys    tmp    usr    var
-------------------code----------------------

- Now we're doing a shell session inside this container.
So let's look around. We have all these directors we're familiar with.
So this is alpine Linux and in this image we also have node.
So if we type node dash dash version, we can see the version of node
which is 14.16.0.

- Now in this image we don't have our application files.
We only have alpine Linux and node. So in the next lesson we're going to show we
how to copy application files into this image.
-------------------code----------------------
/ # node --version
v14.16.0
-------------------code----------------------

*** 6- Copying Files and Directories ***

- Now that we have a base image, the next step is to copy the application
files into the image. So for that we have two instructions, one is
copy, the other is add. They have the exact same syntax,
but add has a couple additional features, we'll talk about that later in this lesson.
-------------------code----------------------
ADD 
COPY
-------------------code----------------------

- So, let's start with copy. With this we can copy one or
more files or directories from the current directory, meaning
this directory over here into the image. So we cannot copy
anything outside of this directory. 

- Here's the reason. When we execute the build command, look at the last argument. A period means the
current directory. So when we execute this command, docker client
sends the content of this directory to docker engine. This is called the
build context. So docker client sends the build context to docker
engine, and then docker engine will start executing these commands
one by one. So at that point, docker engine does not have access
to any files or directories outside of this directory.
-------------------code----------------------
docker build -t react-app .
-------------------code----------------------

- So, here we can copy one or more files. For example, we can copy
package.json into slash app into the image. Now if this directory doesn't exist, docker will automatically
create it.
-------------------code----------------------
COPY package.json /app
-------------------code----------------------

-  We can also copy more than one file, so we can say
readme.md, and by the way, remember this is case sensitive because under the hood we are using
Linux. 
-------------------code----------------------
COPY package.json README.md /app
=> when using COPY with more than one source file, the destination must be a directory and end with a / or a \
-------------------code----------------------

- Now here we have a syntax arrow, look, when using
copy with more than one source file the destination must be a directory
and end with a forward slash. So, here we need to add a
forward slash.
-------------------code----------------------
FROM node:14.16.0-alpine3.13
COPY package.json README.md /app/
-------------------code----------------------

- We can also use patterns. So, let's say, we want to copy all files
that start with package and end with json. So, whatever comes in between
we don't care. That's why we're using a wild card. So, in this directory
we have two files that match this pattern we have package-lock.json
and package.json. Package.json as we told we before includes the list of dependencies
and their versions. But the actual versions that may be installed on this machine
might be a little bit different from what we see here.
So, package-lock.json keeps track of the exact version of these dependencies
installed on this machine.
-------------------code----------------------
COPY package*.json /app/
-------------------code----------------------

- Now, what if we want to copy everything in the current directory into the
app directory? We use a period. So, this is all about source files
and directories.
-------------------code----------------------
COPY . /app/
-------------------code----------------------

-  Now, let's talk about the destination. So, here we're using
an absolute path because our path starts with a forward slash.
We can also use a relative path if we set the working directory first.
So, using the workdir instruction we can set the working directory.
Now, all the instructions that come after will be executed inside
this working directory. And with this we can replace this absolute path
with a relative path. So, we can use a period meaning the current directory. Okay?
-------------------code----------------------
WORKDIR /app
COPY . . 
-------------------code----------------------

- Now, one last thing about copy.
What if we want to copy a file that has
a space in it? So, let's say we have a file called hello world
dot txt. Look, we immediately get a syntax error.
-------------------code----------------------
COPY hello world.txt . 
=> when using COPY with more than one source file, the destination must be a directory and end with a / or a 
-------------------code----------------------

- This is where we use the other form of the
copy instruction. So, copy has another form where
we can pass an array of strings.
-------------------code----------------------
["", "", ""]
-------------------code----------------------

- So, multiple strings. Each string represents an
argument of the copy instruction. So, here, we're going to wrap
all these arguments inside brackets. Then, we're going to wrap
the first item, which is our source file in double quotes.
Then, we add a comma, and wrap the second argument in double quotes.
It's not a form that we use that often, but we thought to cover it to make this less
uncomprehending.
-------------------code----------------------
COPY ["hello world.txt", "."]
-------------------code----------------------

- So, let's simplify things. We're going to copy everything
in our context directory, which is the current directory,
into the current working directory of the image. Okay? Now,
we also have add, it has the exact same syntax as copy,
but add has two additional features. 
-------------------code----------------------
COPY . . 
ADD . .
-------------------code----------------------

- With add, we can add a file from a url, so here we can type
http, some url, and let's say some
file.json. So, if we have access to this file, we can add it to our
image. The other feature is that if we pass
a compressed file, add will automatically uncompress this
into a directory. So, we can use either of these instructions, but the
best practice is to use copy, because it's more straightforward, there's no magic
around it. Use that only if we need one of these additional features.
If we want to add a file from a url, or if we want to uncompress a compressed
file. 
-------------------code----------------------
ADD http://.../file.json .
ADD file.zip .
-------------------code----------------------

- So, let's get rid of this. We're going to copy everything
in the current directory into our image. So, let's go ahead and
rebuild our image. 
-------------------code----------------------
FROM node:14.16.0-alpine3.13
WORKDIR /app
COPY . . 
-------------------code----------------------

- Alright, now look at this line.
Transferring context. So, all the files and directors
in our current directory are being sent to docker engine.
Alright, the image is built, so let's start the container with this image.
-------------------code----------------------
app [master] $ docker build -t react-app .
[+] Building 1.8s (8/8) FINISHED                                                                                                   docker:desktop-linux
 => [internal] load build definition from Dockerfile                                                                                               0.0s
 => => transferring dockerfile: 125B                                                                                                               0.0s
 => [internal] load metadata for docker.io/library/node:14.16.0-alpine3.13                                                                         1.7s
 => [internal] load .dockerignore                                                                                                                  0.0s
 => => transferring context: 2B                                                                                                                    0.0s
 => CACHED [1/3] FROM docker.io/library/node:14.16.0-alpine3.13@sha256:2c51dc462a02f15621e7486774d36d048a27225d581374b002b8477a79a59b4b            0.0s
 => [internal] load build context                                                                                                                  0.0s
 => => transferring context: 546.22kB                                                                                                              0.0s
 => [2/3] WORKDIR /app                                                                                                                             0.0s
 => [3/3] COPY . .                                                                                                                                 0.0s
 => exporting to image                                                                                                                             0.0s
 => => exporting layers                                                                                                                            0.0s
 => => writing image sha256:8816b1815607d3d204cd7f33a3fc141a29e6f96809a6a9a932af2bc578a20463                                                       0.0s
 => => naming to docker.io/library/react-app                                                                                                       0.0s
-------------------code----------------------

- we're going to run shell, so we can look at the file
system. Okay, look, we're inside the app directory,
because in our docker file, we set this directory as the current working
directory. Now, let's run ls. So, here we can see all the files
and directories we have in our project, including node modules.
So, this is all about copying files.
-------------------code----------------------
~  $ docker run -it react-app sh
/app # ls
Dockerfile    README.md     package.json  public        src           yarn.lock
-------------------code----------------------

*** 7- Excluding Files and Directories ***

- In the last lesson we saw that when we build our application, docker
client takes everything in this directory which is called the build context or
the context directory. So docker client takes everything here and sends
it to docker engine or docker daemon. 

- Now for this simple application which has absolutely no features, our build context was about
150 megabytes. But why is it so large? That's the
result of the node modules directory. So if we look over here, we can see
tons of directories and sub directories and this is a very simple project.

- As our application gets more complex and we use more third party
libraries, this node modules directory gets larger and larger. Now
there's a problem here. Later in the course when we talk about deployment, we will see
that our docker client will talk to a docker engine on a different machine.
So that means whatever we have in the build context has to be transferred
over the network. So if we have a large build context with a million files
in it, all these files have to be sent to the docker engine on the remote machine.
We don't want that. We don't really need to transfer this node modules directory
because all these dependencies are defined in package.json. So we can simply exclude this directory
and copy everything else and then restore these dependencies on the target
image. 

- And this has two benefits. The first benefit is that our build context
is smaller. So we transfer less data over the network.
The second benefit is that our build is going to be faster. So we don't have to wait
for all these files to be transferred to docker engine.

- Now how do we exclude this directory? Very easy. we are probably familiar
with the file ".gitignore" With this file, we can exclude some files and directories
from git. Now we have the same concept in docker. So we can
create a file in the root of this project called ignore and everything
is in lowercase. And here we can list the files and directories that should be excluded.
-------------------code----------------------
.dockerignore
-------------------code----------------------
 
- So we can exclude node modules.
Now, when we build a new image, docker will no longer transfer
this large gigantic directory to docker engine. Let's take a look.
So, we're going to run the build command one more time.
-------------------code----------------------
node_modules
-------------------code----------------------

- Look at our build context. It's only 10 kilobytes. So we reduce
our build context from 150 megabytes to 10 kilobytes.
That's a huge improvement. There is a problem though. If we start
a new container and look at the file system
of that container, we're not going to see
the node modules directory because we excluded
it, Let's verify it. 

- So, we're going to run a new container
from react app and then run shell inside that container.
Now in the app directory, let's look at all the files and directories.
Look, we only have two directories here, public and source. So node modules
is not here. This is where we need to run
npm install to install this dependencies. And that's what we will do next.
-------------------code----------------------
/app # ls
Dockerfile    README.md     package.json  public        src           yarn.lock
-------------------code----------------------

*** 8- Running Commands ***

- Alright, the next step is to install
our project dependencies using npm. This is where we use the run command.

- With this command, we can execute any commands that we normally execute
in a terminal session. So we can run npm install, we can also run any of the Linux or Windows commands.
For example, let's say we want to install Python on this image as well.
We can use apt or apt-get to install Python.
-------------------code----------------------
RUN npm install
RUN apt install python
-------------------code----------------------
- Now if we run this, we're going to get an error because alpine Linux doesn't have
apt package manager. It has another package manager called
APK. So be aware of these differences depending on the type of Linux
or Windows we're using.

- So, we don't need to do this in this lesson. Let's just install the dependencies of our project.
So, now, back to our terminal, let's rebuild the image.
-------------------code----------------------
FROM node:14.16.0-alpine3.13
WORKDIR /app
COPY . . 
RUN npm install
-------------------code----------------------

- Alright, so now, docker engine is running npm install to download and install
these dependencies. This is going to take a few seconds, our image is ready.
-------------------code----------------------
app [master] $ docker build -t react-app .
[+] Building 10.5s (7/8)                                                                                                           docker:desktop-linux
 => [internal] load build definition from Dockerfile                                                                                               0.0s
 => => transferring dockerfile: 141B                                                                                                               0.0s
 => [internal] load metadata for docker.io/library/node:14.16.0-alpine3.13                                                                         4.7s
 => [internal] load .dockerignore                                                                                                                  0.0s
 => => transferring context: 89B                                                                                                                   0.0s
 => [1/4] FROM docker.io/library/node:14.16.0-alpine3.13@sha256:2c51dc462a02f15621e7486774d36d048a27225d581374b002b8477a79a59b4b                   0.0s
 => [internal] load build context                                                                                                                  0.0s
 => => transferring context: 1.67kB                                                                                                                0.0s
 => CACHED [2/4] WORKDIR /app                                                                                                                      0.0s
 => [3/4] COPY . .                                                                                                                                 0.0s
 => [4/4] RUN npm install                                                                                                                          5.7s
 => => # npm WARN deprecated
 .....
-------------------code----------------------

- So, let's start a new container with this image
and run shell. Good. Now let's look at our app directory.
Alright, and here we have the node modules directory.
Beautiful. So, we're done with this step.
-------------------code----------------------
~  $ docker run -it react-app sh
/app # ls
Dockerfile         node_modules       package.json       src
README.md          package-lock.json  public             yarn.lock
-------------------code----------------------

*** 9- Setting Environment Variables ***

- Sometimes we need to set environment variables. For example, let's say
this frontend application needs to talk to a backend or an API.

- Quite often we set the URL of the API using an environment variable.
This is where we use the end instruction, so we can set API URL to, let's say, http, api
my-app.com, whatever, doesn't really matter.
-------------------code----------------------
ENV API_URL=http://api.myapp.com/
-------------------code----------------------

- We also have an older syntax without an equal sign that also works.
-------------------code----------------------
ENV API_URL http://api.myapp.com/
-------------------code----------------------

- personally prefer to have an equal sign so we can clearly see the value
of environment variables, but that's just my personal preference.

- Now, let's rebuild the image and inspect this environment variable in our
container. So, we're going to rebuild the image.
-------------------code----------------------
FROM node:14.16.0-alpine3.13
WORKDIR /app
COPY . . 
RUN npm install
ENV API_URL=http://api.myapp.com/
-------------------code----------------------

- the image is built, so let's start a new container.
Now, do we remember the command that we use for inspecting environment variables?
We have a few options. One way is to use printenv to see all environment variables, so we can see
API URL over here.
-------------------code----------------------
~  $ docker run -it react-app sh
/app # printenv API_URL
http://api.myapp.com/
-------------------code----------------------

- We can also print the value of a particular environment variable. Another option is to use
echo, but here we have to use a dollar sign to print API
URL.
-------------------code----------------------
/app # echo $API_URL
http://api.myapp.com/
-------------------code----------------------

- so now whenever we start this container,
this environment variable is automatically set for us.
